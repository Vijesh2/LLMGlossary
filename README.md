# LLMGlossary

### LLM (Large Language Model)

A type of AI model trained on vast amounts of text data to understand and generate human-like language. It predicts the most likely sequence of words based on input and is used for tasks like chatbots, summarization, and translation. e.g gpt-4o, gpt-4o-mini, o1-mini, claude-3-5-sonnet-20241022, claude-3-sonnet-20240229, gemini-1.5-pro, Llama 3.2 3B

---

### LLM vs AI Assistant

An **LLM** is the underlying AI model capable of processing and generating language.  
An **AI Assistant** uses an LLM alongside other systems (e.g., tools, databases, APIs) to perform specific tasks, such as providing tailored responses, executing commands, or automating workflows. e.g. chatgpt, co-pilot, perplexity

---

### LLM Use of Tools

LLMs can interact with external systems (e.g., calculators, search engines, databases) through tool integrations. These extend their capabilities, enabling them to retrieve real-time information or perform operations beyond language generation.

---
### LLM Use of Caching

Caching stores responses or computations from the LLM to reuse them for similar inputs, improving efficiency, consistency, and response time. This is especially useful for repetitive queries or during interactive sessions.

---

### Context

The information provided in the input or conversation that helps the LLM generate relevant and accurate responses. Context includes the current query, prior exchanges, and user instructions, and is limited by the model's context window (a fixed memory size).

---
### Tokens

The individual units of text (e.g., words, parts of words, or characters) that an LLM processes. Text is broken into tokens for efficient computation. For example, "AI is great" could be tokenized as `["AI", " is", " great"]`.

---
### Completion

The output generated by an LLM in response to an input prompt. It predicts and produces text by selecting the most likely sequence of tokens to follow the prompt, based on its training data.

---
### Evals

Short for "evaluations," these are tests or assessments used to measure an LLM's performance. Evals can focus on specific tasks (e.g., accuracy, reasoning, or language generation quality) to ensure the model meets desired standards for effectiveness and reliability.

---
### Chain of Thought

A technique where the LLM generates intermediate reasoning steps before arriving at a final answer. This approach improves accuracy for tasks requiring logical reasoning, multi-step solutions, or complex problem-solving.

---

### Prompt Engineering

The process of designing effective and precise input prompts to guide an LLM's behavior. Good prompts can improve the quality and relevance of the model’s output without modifying the underlying model.

---
### Vector Store

A database optimized for storing and retrieving data as vectors (numerical representations of text, images, etc.). LLMs use vector stores to search and retrieve semantically similar data, enabling efficient handling of large datasets.

---
### Retrieval Augmented Generation (RAG)

A technique that combines LLMs with external retrieval systems (like vector stores) to improve output quality. The model retrieves relevant information from external sources and incorporates it into its response, ensuring accuracy and relevance.

---
### One-Shot Prompting

A prompting technique where the LLM is provided with a single example of the task within the prompt to guide its response. This helps the model understand the desired structure or pattern for the output.

---

### Few-Shot Prompting

A prompting technique where the LLM is provided with a small number of examples (more than one but fewer than many) in the prompt. This helps the model generalize and generate more accurate responses by learning from multiple patterns or contexts.
